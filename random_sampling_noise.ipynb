{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 096: noise; 104-1 channel 2 some segments, channel 1 noise all\n",
    "# 60, 65, 67 (day 5), 83, 91 (ngay 5 bo file 1), 94, 97 (bị ít), 106(1 bi it, 5 nhieu), 107: patterned irregularities \n",
    "\n",
    "# 65, 106-5: not included\n",
    "# 73.1 73.5 noise (hoac nhip tim thay doi dot ngot, ko regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dict = {\n",
    "    '096-1.csv': ['# ECG Channel 1'],\n",
    "    '096-5.csv': ['# ECG Channel 1'],\n",
    "    '104-5.csv': ['# ECG Channel 1', 'ECG Channel 2'],\n",
    "    '060-5.csv': ['# ECG Channel 1'],\n",
    "    '065-5.csv': ['# ECG Channel 1'],\n",
    "    '067-5.csv': ['# ECG Channel 1'],\n",
    "    '083-1.csv': ['# ECG Channel 1'],\n",
    "    '091-5.2.csv': ['# ECG Channel 1'],\n",
    "    '094-1.csv': ['# ECG Channel 1'],\n",
    "    '094-5.csv': ['# ECG Channel 1'],\n",
    "    '097-5.csv': ['# ECG Channel 1'],\n",
    "    '106-1.csv': ['# ECG Channel 1'],\n",
    "    '106-5.2.csv': ['# ECG Channel 1'],\n",
    "    '107-5.csv': ['# ECG Channel 1'],\n",
    "    '073-1.csv': ['# ECG Channel 1'],\n",
    "    '073-5.csv': ['# ECG Channel 1']\n",
    "}\n",
    "FILE_PATH = '/media/tuan/NGUI GA/ECG_cleaned'\n",
    "DATA_POINTS = 7680\n",
    "SAMPLE_PER_FILE = 15\n",
    "FILE_COUNT = 0\n",
    "for entry in noise_dict:\n",
    "    FILE_COUNT += len(noise_dict[entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "file_count_range = list(range(1, FILE_COUNT * SAMPLE_PER_FILE + 1, 1))\n",
    "kf.get_n_splits(file_count_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(file_count_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(map(lambda f: f[1], folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  4,   5,  19,  20,  24,  29,  31,  33,  37,  42,  52,  53,  71,\n",
       "         79,  80,  85,  89, 100, 107, 127, 128, 130, 136, 141, 148, 150,\n",
       "        159, 167, 172, 173, 177, 181, 182, 190, 191, 192, 196, 198, 200,\n",
       "        202, 206, 218, 219, 223, 231, 232, 235, 236, 242, 244, 248]),\n",
       " array([  8,  10,  11,  21,  23,  26,  35,  41,  50,  54,  61,  62,  72,\n",
       "         77,  81,  82,  90,  91,  95, 112, 119, 120, 122, 125, 142, 147,\n",
       "        151, 152, 156, 157, 160, 161, 166, 170, 171, 175, 183, 188, 197,\n",
       "        199, 204, 205, 209, 212, 213, 221, 222, 229, 239, 243, 247]),\n",
       " array([  0,   7,  13,  16,  27,  28,  30,  36,  38,  40,  44,  45,  46,\n",
       "         59,  60,  63,  65,  74,  88,  93, 104, 108, 110, 114, 116, 121,\n",
       "        132, 133, 137, 140, 143, 144, 145, 163, 165, 169, 178, 184, 185,\n",
       "        186, 193, 201, 207, 210, 211, 215, 216, 217, 227, 238, 241]),\n",
       " array([  1,   3,   6,   9,  12,  14,  15,  18,  22,  25,  34,  43,  48,\n",
       "         51,  56,  58,  64,  67,  69,  70,  75,  76,  86,  87, 101, 103,\n",
       "        115, 117, 129, 131, 134, 138, 139, 146, 149, 154, 155, 158, 162,\n",
       "        168, 179, 187, 194, 203, 226, 228, 233, 234, 245, 249, 253]),\n",
       " array([  2,  17,  32,  39,  47,  49,  55,  57,  66,  68,  73,  78,  83,\n",
       "         84,  92,  94,  96,  97,  98,  99, 102, 105, 106, 109, 111, 113,\n",
       "        118, 123, 124, 126, 135, 153, 164, 174, 176, 180, 189, 195, 208,\n",
       "        214, 220, 224, 225, 230, 237, 240, 246, 250, 251, 252, 254])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(file_index):\n",
    "    for i, f in enumerate(folds):\n",
    "        if file_index in f:\n",
    "            return i + 1\n",
    "    print(file_index)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(in_path):\n",
    "    csv_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
    "        for file in filenames:\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            ext = str.lower(ext)\n",
    "            if ext == '.csv':\n",
    "                csv_files.append(os.path.join(dirpath, file))\n",
    "    csv_files.sort()\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_n_number(n, max_n, min_difference=7680):\n",
    "    return sorted(random.sample(range(0, max_n, min_difference), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7680, 46080, 76800, 122880, 161280, 176640, 230400, 253440, 261120, 268800]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_n_number(10, 300000, 7680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './splitted/'\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './splitted/output'\n",
    "if not os.path.isdir(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    fold_path = f'./splitted/output/{i}'\n",
    "    if not os.path.isdir(fold_path):\n",
    "        os.mkdir(fold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "096-1.csv ['# ECG Channel 1']\n",
      "096-5.csv ['# ECG Channel 1']\n",
      "104-5.csv ['# ECG Channel 1', 'ECG Channel 2']\n",
      "104-5.csv ['# ECG Channel 1', 'ECG Channel 2']\n",
      "060-5.csv ['# ECG Channel 1']\n",
      "065-5.csv ['# ECG Channel 1']\n",
      "067-5.csv ['# ECG Channel 1']\n",
      "083-1.csv ['# ECG Channel 1']\n",
      "091-5.2.csv ['# ECG Channel 1']\n",
      "094-1.csv ['# ECG Channel 1']\n",
      "094-5.csv ['# ECG Channel 1']\n",
      "097-5.csv ['# ECG Channel 1']\n",
      "106-1.csv ['# ECG Channel 1']\n",
      "106-5.2.csv ['# ECG Channel 1']\n",
      "107-5.csv ['# ECG Channel 1']\n",
      "073-1.csv ['# ECG Channel 1']\n",
      "073-5.csv ['# ECG Channel 1']\n"
     ]
    }
   ],
   "source": [
    "ground_truth = pd.DataFrame(columns=['file', 'begin', 'end', 'original', 'fold'])\n",
    "file_index = 0\n",
    "file_output_folder = f'./splitted/output'\n",
    "if not os.path.isdir(file_output_folder):\n",
    "    os.mkdir(file_output_folder)\n",
    "for entry in noise_dict:\n",
    "    full_file_path = f\"{FILE_PATH}/{entry}\"\n",
    "    df = pd.read_csv(full_file_path)\n",
    "    channels = noise_dict[entry]\n",
    "    for channel in channels:\n",
    "        print(entry, channels)\n",
    "        channel_data = df[channel]\n",
    "        max_channel_len = len(channel_data.values)\n",
    "        random_timepoints = generate_random_n_number(SAMPLE_PER_FILE, max_channel_len - 10000, 7680)\n",
    "        \n",
    "        for time_index, timepoint in enumerate(random_timepoints):\n",
    "            partial_df = channel_data[timepoint: timepoint + 7680]\n",
    "            partial_filename = f'{file_index}.csv'\n",
    "            \n",
    "            file_fold = get_fold(file_index)\n",
    "            file_output_folder = f'./splitted/output/{file_fold}'\n",
    "            \n",
    "            partial_df.to_csv(f'{file_output_folder}/{partial_filename}', header=False, index=False)\n",
    "            ground_truth = ground_truth.append({\n",
    "                'file': partial_filename,\n",
    "                'begin': timepoint,\n",
    "                'end': timepoint + 7680,\n",
    "                'original': entry,\n",
    "                'channel': channel,\n",
    "                'fold': file_fold\n",
    "            }, ignore_index=True)\n",
    "            file_index += 1\n",
    "\n",
    "ground_truth.to_csv(f'{output_folder}/gt.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
