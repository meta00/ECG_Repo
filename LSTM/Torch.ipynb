{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/tuan/NGUI GA/ECG_split/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def get_np_arrays(file_name):\n",
    "    scaler = StandardScaler()\n",
    "    arr = pd.read_csv(path + file_name)['# ECG Channel 1'].values.reshape(-1, 1)\n",
    "    \n",
    "    seq_len = arr.shape[0]\n",
    "    \n",
    "    result = np.zeros([76800, 1])\n",
    "    result[:arr.shape[0],:arr.shape[1]] = arr\n",
    "    \n",
    "    scaler.fit(result)\n",
    "    result = scaler.transform(result)\n",
    "    return torch.from_numpy(result).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2610],\n",
       "        [-0.2744],\n",
       "        [-0.3148],\n",
       "        ...,\n",
       "        [ 0.2371],\n",
       "        [ 0.0890],\n",
       "        [-0.0725]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_np_arrays('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mapped_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['data_type'] == 'test']\n",
    "train_df = df[df['data_type'] == 'train']\n",
    "val_df = df[df['data_type'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filenames = train_df['file'].values.tolist()\n",
    "y_train = train_df['class'].values.tolist()\n",
    "\n",
    "X_val_filenames = val_df['file'].values.tolist()\n",
    "y_val = val_df['class'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self, series_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.series_IDs = series_IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.series_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.series_IDs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = get_np_arrays(ID)\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "training_set = Dataset(X_train_filenames, y_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = Dataset(X_val_filenames, y_val)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBaseline(nn.Module):\n",
    "    \"\"\"A PyTorch implementation of the Linear Baseline\n",
    "    From https://arxiv.org/abs/1909.04939\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    sequence_length:\n",
    "        The size of the input sequence\n",
    "    num_pred_classes:\n",
    "        The number of output classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs: int, num_pred_classes: int = 1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # for easier saving and loading\n",
    "        self.input_args = {\n",
    "            'num_inputs': num_inputs,\n",
    "            'num_pred_classes': num_pred_classes\n",
    "        }\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            LinearBlock(num_inputs, 500, 0.2),\n",
    "            LinearBlock(500, 500, 0.2),\n",
    "            LinearBlock(500, num_pred_classes, 0.3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        return self.layers(x.view(x.shape[0], -1))\n",
    "\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int,\n",
    "                 dropout: float) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = 64\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(1, 16, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = (0, 1)\n",
    "input_dim = 1    \n",
    "hidden_dim = 256\n",
    "layer_dim = 1\n",
    "output_dim = 2\n",
    "seq_dim = 128\n",
    "\n",
    "model = LSTMClassifier(1, 16, 2, 2)\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, data in enumerate(validation_generator, 0):\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(local_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += local_labels.size(0)\n",
    "                correct += (predicted == local_labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "                    100 * correct / total))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over epochs\n",
    "# infer_time = 0\n",
    "start_time = time.time()\n",
    "best_accuracy = -1\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    print(f\"Current epoch: {epoch}\")\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(training_generator, 0):\n",
    "        model.train()\n",
    "        print(f\"Current i: {i}\")\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        # Model computations\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        start_time = time.time()\n",
    "        \n",
    "        outputs = model(local_batch)\n",
    "        \n",
    "#         forward_time = time.time() - start_time\n",
    "#         infer_time += forward_time\n",
    "        loss = criterion(outputs, local_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 200 mini-batches\n",
    "            elapsed_time = time.time() - start_time\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_acc = validation(model)\n",
    "                print(f\"Validation accuracy: {val_acc}\")\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
