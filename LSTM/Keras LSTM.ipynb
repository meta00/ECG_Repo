{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout\n",
    "from tensorflow.keras.layers import multiply, concatenate, Activation, Masking, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('gt_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./RR/\" \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def get_np_arrays(file_name):\n",
    "    arr = pd.read_csv(f'{file_name}', header=None, names=['R'])['R'].values.reshape(-1, 1)\n",
    "    \n",
    "    seq_len = arr.shape[0]\n",
    "    \n",
    "    result = np.zeros([599, 1])\n",
    "    result[:arr.shape[0],:arr.shape[1]] = arr\n",
    "    \n",
    "    #scaler.fit(result)\n",
    "    #result = scaler.transform(result)\n",
    "#     print(file_name)\n",
    "#     arr = pd.read_csv(path + file_name)['# ECG Channel 1'].values\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[168.],\n",
       "       [168.],\n",
       "       [166.],\n",
       "       [153.],\n",
       "       [179.],\n",
       "       [165.],\n",
       "       [165.],\n",
       "       [165.],\n",
       "       [164.],\n",
       "       [151.],\n",
       "       [164.],\n",
       "       [178.],\n",
       "       [151.],\n",
       "       [179.],\n",
       "       [165.],\n",
       "       [155.],\n",
       "       [180.],\n",
       "       [167.],\n",
       "       [166.],\n",
       "       [151.],\n",
       "       [176.],\n",
       "       [159.],\n",
       "       [157.],\n",
       "       [156.],\n",
       "       [152.],\n",
       "       [137.],\n",
       "       [149.],\n",
       "       [148.],\n",
       "       [162.],\n",
       "       [148.],\n",
       "       [137.],\n",
       "       [153.],\n",
       "       [168.],\n",
       "       [157.],\n",
       "       [159.],\n",
       "       [162.],\n",
       "       [148.],\n",
       "       [177.],\n",
       "       [165.],\n",
       "       [165.],\n",
       "       [169.],\n",
       "       [165.],\n",
       "       [169.],\n",
       "       [168.],\n",
       "       [169.],\n",
       "       [176.],\n",
       "       [169.],\n",
       "       [172.],\n",
       "       [170.],\n",
       "       [169.],\n",
       "       [168.],\n",
       "       [169.],\n",
       "       [167.],\n",
       "       [167.],\n",
       "       [166.],\n",
       "       [155.],\n",
       "       [179.],\n",
       "       [166.],\n",
       "       [166.],\n",
       "       [151.],\n",
       "       [176.],\n",
       "       [163.],\n",
       "       [162.],\n",
       "       [162.],\n",
       "       [163.],\n",
       "       [162.],\n",
       "       [149.],\n",
       "       [176.],\n",
       "       [161.],\n",
       "       [159.],\n",
       "       [161.],\n",
       "       [145.],\n",
       "       [158.],\n",
       "       [172.],\n",
       "       [159.],\n",
       "       [157.],\n",
       "       [145.],\n",
       "       [171.],\n",
       "       [156.],\n",
       "       [141.],\n",
       "       [154.],\n",
       "       [165.],\n",
       "       [151.],\n",
       "       [137.],\n",
       "       [166.],\n",
       "       [154.],\n",
       "       [144.],\n",
       "       [161.],\n",
       "       [164.],\n",
       "       [178.],\n",
       "       [165.],\n",
       "       [165.],\n",
       "       [152.],\n",
       "       [178.],\n",
       "       [143.],\n",
       "       [185.],\n",
       "       [165.],\n",
       "       [159.],\n",
       "       [164.],\n",
       "       [167.],\n",
       "       [171.],\n",
       "       [155.],\n",
       "       [182.],\n",
       "       [156.],\n",
       "       [185.],\n",
       "       [171.],\n",
       "       [159.],\n",
       "       [171.],\n",
       "       [184.],\n",
       "       [156.],\n",
       "       [184.],\n",
       "       [157.],\n",
       "       [186.],\n",
       "       [170.],\n",
       "       [171.],\n",
       "       [172.],\n",
       "       [161.],\n",
       "       [186.],\n",
       "       [175.],\n",
       "       [164.],\n",
       "       [191.],\n",
       "       [176.],\n",
       "       [173.],\n",
       "       [178.],\n",
       "       [179.],\n",
       "       [182.],\n",
       "       [174.],\n",
       "       [180.],\n",
       "       [181.],\n",
       "       [179.],\n",
       "       [165.],\n",
       "       [197.],\n",
       "       [166.],\n",
       "       [193.],\n",
       "       [175.],\n",
       "       [176.],\n",
       "       [176.],\n",
       "       [160.],\n",
       "       [189.],\n",
       "       [175.],\n",
       "       [179.],\n",
       "       [173.],\n",
       "       [178.],\n",
       "       [180.],\n",
       "       [164.],\n",
       "       [191.],\n",
       "       [180.],\n",
       "       [179.],\n",
       "       [177.],\n",
       "       [179.],\n",
       "       [179.],\n",
       "       [179.],\n",
       "       [180.],\n",
       "       [182.],\n",
       "       [181.],\n",
       "       [178.],\n",
       "       [181.],\n",
       "       [174.],\n",
       "       [177.],\n",
       "       [180.],\n",
       "       [168.],\n",
       "       [185.],\n",
       "       [193.],\n",
       "       [180.],\n",
       "       [181.],\n",
       "       [180.],\n",
       "       [174.],\n",
       "       [162.],\n",
       "       [173.],\n",
       "       [184.],\n",
       "       [172.],\n",
       "       [176.],\n",
       "       [173.],\n",
       "       [157.],\n",
       "       [171.],\n",
       "       [183.],\n",
       "       [170.],\n",
       "       [155.],\n",
       "       [182.],\n",
       "       [171.],\n",
       "       [169.],\n",
       "       [170.],\n",
       "       [170.],\n",
       "       [172.],\n",
       "       [171.],\n",
       "       [172.],\n",
       "       [172.],\n",
       "       [175.],\n",
       "       [173.],\n",
       "       [159.],\n",
       "       [174.],\n",
       "       [185.],\n",
       "       [173.],\n",
       "       [159.],\n",
       "       [187.],\n",
       "       [160.],\n",
       "       [188.],\n",
       "       [173.],\n",
       "       [171.],\n",
       "       [156.],\n",
       "       [168.],\n",
       "       [165.],\n",
       "       [164.],\n",
       "       [161.],\n",
       "       [171.],\n",
       "       [157.],\n",
       "       [154.],\n",
       "       [137.],\n",
       "       [150.],\n",
       "       [162.],\n",
       "       [151.],\n",
       "       [151.],\n",
       "       [152.],\n",
       "       [155.],\n",
       "       [143.],\n",
       "       [173.],\n",
       "       [164.],\n",
       "       [154.],\n",
       "       [167.],\n",
       "       [186.],\n",
       "       [159.],\n",
       "       [188.],\n",
       "       [173.],\n",
       "       [166.],\n",
       "       [182.],\n",
       "       [193.],\n",
       "       [179.],\n",
       "       [181.],\n",
       "       [180.],\n",
       "       [177.],\n",
       "       [175.],\n",
       "       [163.],\n",
       "       [193.],\n",
       "       [165.],\n",
       "       [192.],\n",
       "       [179.],\n",
       "       [167.],\n",
       "       [195.],\n",
       "       [179.],\n",
       "       [179.],\n",
       "       [183.],\n",
       "       [182.],\n",
       "       [181.],\n",
       "       [165.],\n",
       "       [192.],\n",
       "       [181.],\n",
       "       [177.],\n",
       "       [176.],\n",
       "       [179.],\n",
       "       [180.],\n",
       "       [164.],\n",
       "       [190.],\n",
       "       [164.],\n",
       "       [191.],\n",
       "       [176.],\n",
       "       [177.],\n",
       "       [177.],\n",
       "       [178.],\n",
       "       [175.],\n",
       "       [174.],\n",
       "       [177.],\n",
       "       [180.],\n",
       "       [177.],\n",
       "       [179.],\n",
       "       [165.],\n",
       "       [190.],\n",
       "       [163.],\n",
       "       [189.],\n",
       "       [175.],\n",
       "       [173.],\n",
       "       [173.],\n",
       "       [169.],\n",
       "       [157.],\n",
       "       [182.],\n",
       "       [169.],\n",
       "       [167.],\n",
       "       [166.],\n",
       "       [152.],\n",
       "       [173.],\n",
       "       [161.],\n",
       "       [144.],\n",
       "       [154.],\n",
       "       [166.],\n",
       "       [153.],\n",
       "       [153.],\n",
       "       [154.],\n",
       "       [156.],\n",
       "       [145.],\n",
       "       [175.],\n",
       "       [166.],\n",
       "       [167.],\n",
       "       [170.],\n",
       "       [172.],\n",
       "       [165.],\n",
       "       [184.],\n",
       "       [195.],\n",
       "       [180.],\n",
       "       [184.],\n",
       "       [183.],\n",
       "       [168.],\n",
       "       [197.],\n",
       "       [183.],\n",
       "       [181.],\n",
       "       [178.],\n",
       "       [169.],\n",
       "       [181.],\n",
       "       [192.],\n",
       "       [181.],\n",
       "       [182.],\n",
       "       [180.],\n",
       "       [165.],\n",
       "       [194.],\n",
       "       [170.],\n",
       "       [194.],\n",
       "       [181.],\n",
       "       [183.],\n",
       "       [167.],\n",
       "       [192.],\n",
       "       [181.],\n",
       "       [180.],\n",
       "       [176.],\n",
       "       [178.],\n",
       "       [166.],\n",
       "       [194.],\n",
       "       [175.],\n",
       "       [179.],\n",
       "       [181.],\n",
       "       [183.],\n",
       "       [168.],\n",
       "       [182.],\n",
       "       [197.],\n",
       "       [182.],\n",
       "       [182.],\n",
       "       [183.],\n",
       "       [182.],\n",
       "       [181.],\n",
       "       [168.],\n",
       "       [182.],\n",
       "       [195.],\n",
       "       [181.],\n",
       "       [183.],\n",
       "       [169.],\n",
       "       [181.],\n",
       "       [195.],\n",
       "       [180.],\n",
       "       [180.],\n",
       "       [179.],\n",
       "       [178.],\n",
       "       [175.],\n",
       "       [177.],\n",
       "       [177.],\n",
       "       [162.],\n",
       "       [192.],\n",
       "       [179.],\n",
       "       [179.],\n",
       "       [181.],\n",
       "       [184.],\n",
       "       [181.],\n",
       "       [180.],\n",
       "       [169.],\n",
       "       [193.],\n",
       "       [180.],\n",
       "       [179.],\n",
       "       [178.],\n",
       "       [176.],\n",
       "       [180.],\n",
       "       [181.],\n",
       "       [177.],\n",
       "       [178.],\n",
       "       [163.],\n",
       "       [187.],\n",
       "       [172.],\n",
       "       [174.],\n",
       "       [175.],\n",
       "       [173.],\n",
       "       [173.],\n",
       "       [175.],\n",
       "       [174.],\n",
       "       [172.],\n",
       "       [173.],\n",
       "       [159.],\n",
       "       [183.],\n",
       "       [170.],\n",
       "       [157.],\n",
       "       [183.],\n",
       "       [170.],\n",
       "       [169.],\n",
       "       [167.],\n",
       "       [165.],\n",
       "       [163.],\n",
       "       [147.],\n",
       "       [170.],\n",
       "       [155.],\n",
       "       [139.],\n",
       "       [151.],\n",
       "       [164.],\n",
       "       [139.],\n",
       "       [166.],\n",
       "       [155.],\n",
       "       [156.],\n",
       "       [159.],\n",
       "       [150.],\n",
       "       [177.],\n",
       "       [167.],\n",
       "       [169.],\n",
       "       [166.],\n",
       "       [158.],\n",
       "       [187.],\n",
       "       [172.],\n",
       "       [162.],\n",
       "       [188.],\n",
       "       [177.],\n",
       "       [160.],\n",
       "       [188.],\n",
       "       [174.],\n",
       "       [176.],\n",
       "       [174.],\n",
       "       [162.],\n",
       "       [191.],\n",
       "       [176.],\n",
       "       [178.],\n",
       "       [177.],\n",
       "       [179.],\n",
       "       [175.],\n",
       "       [175.],\n",
       "       [177.],\n",
       "       [177.],\n",
       "       [176.],\n",
       "       [177.],\n",
       "       [167.],\n",
       "       [194.],\n",
       "       [178.],\n",
       "       [181.],\n",
       "       [169.],\n",
       "       [191.],\n",
       "       [177.],\n",
       "       [178.],\n",
       "       [174.],\n",
       "       [172.],\n",
       "       [171.],\n",
       "       [158.],\n",
       "       [182.],\n",
       "       [155.],\n",
       "       [184.],\n",
       "       [160.],\n",
       "       [187.],\n",
       "       [176.],\n",
       "       [175.],\n",
       "       [176.],\n",
       "       [180.],\n",
       "       [179.],\n",
       "       [181.],\n",
       "       [178.],\n",
       "       [180.],\n",
       "       [182.],\n",
       "       [168.],\n",
       "       [192.],\n",
       "       [183.],\n",
       "       [184.],\n",
       "       [168.],\n",
       "       [195.],\n",
       "       [172.],\n",
       "       [200.],\n",
       "       [185.],\n",
       "       [183.],\n",
       "       [171.],\n",
       "       [193.],\n",
       "       [179.],\n",
       "       [167.],\n",
       "       [192.],\n",
       "       [178.],\n",
       "       [181.],\n",
       "       [181.],\n",
       "       [180.],\n",
       "       [184.],\n",
       "       [184.],\n",
       "       [170.],\n",
       "       [197.],\n",
       "       [183.],\n",
       "       [180.],\n",
       "       [180.],\n",
       "       [180.],\n",
       "       [163.],\n",
       "       [190.],\n",
       "       [178.],\n",
       "       [166.],\n",
       "       [191.],\n",
       "       [162.],\n",
       "       [192.],\n",
       "       [176.],\n",
       "       [162.],\n",
       "       [190.],\n",
       "       [177.],\n",
       "       [176.],\n",
       "       [176.],\n",
       "       [180.],\n",
       "       [169.],\n",
       "       [192.],\n",
       "       [180.],\n",
       "       [182.],\n",
       "       [165.],\n",
       "       [190.],\n",
       "       [179.],\n",
       "       [178.],\n",
       "       [164.],\n",
       "       [178.],\n",
       "       [180.],\n",
       "       [178.],\n",
       "       [192.],\n",
       "       [177.],\n",
       "       [179.],\n",
       "       [177.],\n",
       "       [179.],\n",
       "       [167.],\n",
       "       [192.],\n",
       "       [178.],\n",
       "       [178.],\n",
       "       [176.],\n",
       "       [175.],\n",
       "       [176.],\n",
       "       [176.],\n",
       "       [176.],\n",
       "       [175.],\n",
       "       [177.],\n",
       "       [178.],\n",
       "       [176.],\n",
       "       [179.],\n",
       "       [178.],\n",
       "       [180.],\n",
       "       [173.],\n",
       "       [166.],\n",
       "       [177.],\n",
       "       [190.],\n",
       "       [177.],\n",
       "       [176.],\n",
       "       [160.],\n",
       "       [189.],\n",
       "       [174.],\n",
       "       [173.],\n",
       "       [173.],\n",
       "       [176.],\n",
       "       [173.],\n",
       "       [177.],\n",
       "       [172.],\n",
       "       [174.],\n",
       "       [173.],\n",
       "       [163.],\n",
       "       [188.],\n",
       "       [173.],\n",
       "       [177.],\n",
       "       [161.],\n",
       "       [191.],\n",
       "       [171.],\n",
       "       [172.],\n",
       "       [170.],\n",
       "       [167.],\n",
       "       [166.],\n",
       "       [163.],\n",
       "       [162.],\n",
       "       [160.],\n",
       "       [160.],\n",
       "       [157.],\n",
       "       [143.],\n",
       "       [155.],\n",
       "       [166.],\n",
       "       [138.],\n",
       "       [163.],\n",
       "       [150.],\n",
       "       [138.],\n",
       "       [152.],\n",
       "       [168.],\n",
       "       [160.],\n",
       "       [157.],\n",
       "       [160.],\n",
       "       [165.],\n",
       "       [166.],\n",
       "       [168.],\n",
       "       [167.],\n",
       "       [170.],\n",
       "       [150.],\n",
       "       [193.],\n",
       "       [172.],\n",
       "       [162.],\n",
       "       [189.],\n",
       "       [175.],\n",
       "       [176.],\n",
       "       [180.],\n",
       "       [168.],\n",
       "       [193.],\n",
       "       [184.],\n",
       "       [171.],\n",
       "       [192.],\n",
       "       [179.],\n",
       "       [177.],\n",
       "       [161.],\n",
       "       [173.],\n",
       "       [172.],\n",
       "       [185.],\n",
       "       [168.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_np_arrays('./RR/095-1_181|0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(599, 1),\n",
    "                 n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = get_np_arrays(ID)\n",
    "\n",
    "            # Store class\n",
    "            y[i] = df[df['file'] == ID]['class'].astype('float32')\n",
    "#         return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)        \n",
    "        return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['data_type'] == 'test']\n",
    "train_df = df[df['data_type'] == 'train']\n",
    "val_df = df[df['data_type'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.asarray([get_np_arrays('1.csv'), get_np_arrays('2.csv'), \\\n",
    "#                      get_np_arrays('8.csv'), get_np_arrays('9.csv'), \\\n",
    "#                      get_np_arrays('10.csv')])\n",
    "# X_val = np.asarray([get_np_arrays('5.csv'), get_np_arrays('6.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filenames = train_df['file'].values.tolist()\n",
    "# y_train = np.asarray([1, 0, 1, 0, 1])\n",
    "\n",
    "X_val_filenames = val_df['file'].values.tolist()\n",
    "# y_val = np.asarray([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_filenames = train_df['file'].values.tolist()\n",
    "# y_train = train_df['class'].values.tolist()\n",
    "\n",
    "# X_val_filenames = val_df['file'].values.tolist()\n",
    "# y_val = val_df['class'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(X_train_filenames, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_val_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(599, 1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    filters = input.shape[-1] # channel_axis = -1 for TF\n",
    "\n",
    "    se = GlobalAveragePooling1D()(input)\n",
    "    se = Reshape((1, filters))(se)\n",
    "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = multiply([input, se])\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(599, 1))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(8)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = squeeze_excite_block(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 599, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 1, 599)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1, 128)       613504      permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1, 128)       512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1, 128)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 128)       0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 8)         1024        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 128)       1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1, 128)       0           activation[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1, 256)       164096      multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1, 256)       1024        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 256)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 256)       0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 16)        4096        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 256)       4096        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1, 256)       0           activation_1[0][0]               \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 128)       98432       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 599, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1, 128)       512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 8)            320         masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1, 128)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8)            0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 136)          0           dropout[0][0]                    \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            274         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 888,914\n",
      "Trainable params: 887,890\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 264,449\n",
      "Trainable params: 264,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.7590 - accuracy: 0.4995WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 379ms/step - loss: 0.7590 - accuracy: 0.4995 - val_loss: 0.6954 - val_accuracy: 0.5735\n",
      "Epoch 2/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4652WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 374ms/step - loss: 0.6934 - accuracy: 0.4652 - val_loss: 0.6948 - val_accuracy: 0.5771\n",
      "Epoch 3/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.4782WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 372ms/step - loss: 0.6933 - accuracy: 0.4782 - val_loss: 0.6949 - val_accuracy: 0.4226\n",
      "Epoch 4/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5267WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 373ms/step - loss: 0.6936 - accuracy: 0.5267 - val_loss: 0.6932 - val_accuracy: 0.4221\n",
      "Epoch 5/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4939WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 373ms/step - loss: 0.6931 - accuracy: 0.4939 - val_loss: 0.6933 - val_accuracy: 0.4229\n",
      "Epoch 6/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 375ms/step - loss: 0.6931 - accuracy: 0.4779 - val_loss: 0.6934 - val_accuracy: 0.3030\n",
      "Epoch 7/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4728WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 374ms/step - loss: 0.6931 - accuracy: 0.4728 - val_loss: 0.6935 - val_accuracy: 0.3901\n",
      "Epoch 8/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4822WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 377ms/step - loss: 0.6931 - accuracy: 0.4822 - val_loss: 0.6935 - val_accuracy: 0.5779\n",
      "Epoch 9/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4616WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 367ms/step - loss: 0.6931 - accuracy: 0.4616 - val_loss: 0.6934 - val_accuracy: 0.3311\n",
      "Epoch 10/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 369ms/step - loss: 0.6931 - accuracy: 0.4709 - val_loss: 0.6934 - val_accuracy: 0.3567\n",
      "Epoch 11/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 377ms/step - loss: 0.6932 - accuracy: 0.4827 - val_loss: 0.6934 - val_accuracy: 0.4233\n",
      "Epoch 12/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4848WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 375ms/step - loss: 0.6931 - accuracy: 0.4848 - val_loss: 0.6933 - val_accuracy: 0.4226\n",
      "Epoch 13/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4818WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 52s 377ms/step - loss: 0.6932 - accuracy: 0.4818 - val_loss: 0.6933 - val_accuracy: 0.5762\n",
      "Epoch 14/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4988WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 53s 383ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6933 - val_accuracy: 0.5762\n",
      "Epoch 15/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4772WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 370ms/step - loss: 0.6932 - accuracy: 0.4772 - val_loss: 0.6934 - val_accuracy: 0.5779\n",
      "Epoch 16/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4597WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6931 - accuracy: 0.4597 - val_loss: 0.6933 - val_accuracy: 0.4221\n",
      "Epoch 17/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4589WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6931 - accuracy: 0.4589 - val_loss: 0.6933 - val_accuracy: 0.4224\n",
      "Epoch 18/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4650WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 366ms/step - loss: 0.6931 - accuracy: 0.4650 - val_loss: 0.6933 - val_accuracy: 0.5779\n",
      "Epoch 19/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4942WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6931 - accuracy: 0.4942 - val_loss: 0.6933 - val_accuracy: 0.5757\n",
      "Epoch 20/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5122WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 367ms/step - loss: 0.6936 - accuracy: 0.5122 - val_loss: 0.6943 - val_accuracy: 0.5754\n",
      "Epoch 21/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4895WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6937 - accuracy: 0.4895 - val_loss: 0.6933 - val_accuracy: 0.5762\n",
      "Epoch 22/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6931 - accuracy: 0.4918 - val_loss: 0.6933 - val_accuracy: 0.5754\n",
      "Epoch 23/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 368ms/step - loss: 0.6931 - accuracy: 0.4899 - val_loss: 0.6933 - val_accuracy: 0.4246\n",
      "Epoch 24/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4898WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 369ms/step - loss: 0.6931 - accuracy: 0.4898 - val_loss: 0.6933 - val_accuracy: 0.5793\n",
      "Epoch 25/25\n",
      "138/138 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "138/138 [==============================] - 51s 370ms/step - loss: 0.6931 - accuracy: 0.4905 - val_loss: 0.6933 - val_accuracy: 0.5762\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=0.1)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
    "model2.compile(optimizer=adam, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=200, batch_size=128, callbacks=[chk], validation_data=(X_val,y_val))\n",
    "H = model2.fit(\n",
    "    x=my_training_batch_generator,\n",
    "    validation_data=my_validation_batch_generator,\n",
    "    epochs=25, \n",
    "    batch_size=batch_size,\n",
    "    callbacks=[chk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
